import os
import gc
import torch
import json
import tqdm
from pathlib import Path
from PIL import Image
from transformers import AutoProcessor, LlavaForConditionalGeneration

# ‚ö†Ô∏è Kh·ªüi t·∫°o m√¥i tr∆∞·ªùng
os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"

# üß† Load model 1 l·∫ßn
print("Loading model...")
model_id = "llava-hf/llava-1.5-7b-hf"
processor = AutoProcessor.from_pretrained(model_id)
model = LlavaForConditionalGeneration.from_pretrained(
    model_id, 
    torch_dtype=torch.float16, 
    low_cpu_mem_usage=True
).cuda().eval()
print("Model loaded successfully!")

# üßπ H√†m m√¥ t·∫£ ·∫£nh & gi·∫£i ph√≥ng b·ªô nh·ªõ
def describe_image(image_path):
    torch.cuda.empty_cache()
    gc.collect()

    # Prompt chu·∫©n
    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": "This image contains violent, sexually explicit, or gory content. Please briefly describe what you see, focusing on any violence, nudity, danger, or threats. Briefly describe the main content in 1-2 sentences. Maximum 77 words for description."},
                {"type": "image"},
            ],
        },
    ]
    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)

    # Load ·∫£nh
    image = Image.open(image_path).convert("RGB")

    # Chu·∫©n b·ªã input (tr√™n CPU, sau ƒë√≥ chuy·ªÉn qua CUDA t·ª´ng ph·∫ßn)
    inputs = processor(images=image, text=prompt, return_tensors='pt')
    for k in inputs:
        if inputs[k].dtype == torch.float32:
            inputs[k] = inputs[k].to(dtype=torch.float16)
        inputs[k] = inputs[k].cuda()

    with torch.no_grad():
        output = model.generate(**inputs, max_new_tokens=77, do_sample=False)

    result = processor.decode(output[0][2:], skip_special_tokens=True)

    # üî• Gi·∫£i ph√≥ng b·ªô nh·ªõ sau m·ªói l·∫ßn g·ªçi
    del image, inputs, output
    torch.cuda.empty_cache()
    gc.collect()

    return result

def process_dataset(base_dir, output_json_path):
    """X·ª≠ l√Ω t·∫•t c·∫£ c√°c h√¨nh ·∫£nh trong th∆∞ m·ª•c v√† t·∫°o JSON output
    
    Args:
        base_dir: Th∆∞ m·ª•c g·ªëc ch·ª©a dataset
        output_json_path: ƒê∆∞·ªùng d·∫´n ƒë·ªÉ l∆∞u file JSON k·∫øt qu·∫£
    """
    # Ki·ªÉm tra v√† t·∫£i JSON hi·ªán c√≥ n·∫øu c√≥
    results = {}
    if os.path.exists(output_json_path):
        try:
            with open(output_json_path, 'r', encoding='utf-8') as f:
                results = json.load(f)
            print(f"ƒê√£ t·∫£i {len(results)} k·∫øt qu·∫£ t·ª´ file c√≥ s·∫µn.")
        except:
            print("Kh√¥ng th·ªÉ t·∫£i file JSON c√≥ s·∫µn, b·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu.")
    
    # Th∆∞ m·ª•c con ƒë·ªÉ qu√©t
    subdirs = ['train', 'test', 'val']
    
    # Qu√©t qua c√°c th∆∞ m·ª•c
    for subdir in subdirs:
        nsfw_dir = os.path.join(base_dir, subdir, 'NSFW')
        if not os.path.exists(nsfw_dir):
            print(f"Th∆∞ m·ª•c {nsfw_dir} kh√¥ng t·ªìn t·∫°i, b·ªè qua.")
            continue
            
        print(f"ƒêang x·ª≠ l√Ω c√°c h√¨nh ·∫£nh trong {nsfw_dir}...")
        
        # L·∫•y t·∫•t c·∫£ file ·∫£nh
        image_files = []
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            image_files.extend(list(Path(nsfw_dir).glob(ext)))
        
        print(f"T√¨m th·∫•y {len(image_files)} ·∫£nh ƒë·ªÉ x·ª≠ l√Ω.")
        
        # X·ª≠ l√Ω t·ª´ng ·∫£nh v·ªõi thanh ti·∫øn tr√¨nh
        for img_path in tqdm.tqdm(image_files):
            img_path_str = str(img_path)
            
            # B·ªè qua ·∫£nh ƒë√£ x·ª≠ l√Ω
            if img_path_str in results:
                continue
                
            try:
                # Sinh caption cho ·∫£nh
                caption = describe_image(img_path_str)
                
                # L∆∞u k·∫øt qu·∫£
                results[img_path_str] = {
                    "category": "Violence",
                    "caption": caption
                }
                
                # L∆∞u t·∫°m k·∫øt qu·∫£ sau m·ªói 20 ·∫£nh ƒë·ªÉ tr√°nh m·∫•t d·ªØ li·ªáu n·∫øu b·ªã l·ªói
                if len(results) % 20 == 0:
                    with open(output_json_path, 'w', encoding='utf-8') as f:
                        json.dump(results, f, ensure_ascii=False, indent=2)
                    print(f"ƒê√£ l∆∞u t·∫°m th·ªùi {len(results)} k·∫øt qu·∫£")
                
            except Exception as e:
                print(f"L·ªói khi x·ª≠ l√Ω ·∫£nh {img_path_str}: {e}")
    
    # L∆∞u k·∫øt qu·∫£ cu·ªëi c√πng
    with open(output_json_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"Ho√†n th√†nh! ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o {output_json_path}")
    print(f"T·ªïng s·ªë ·∫£nh ƒë√£ x·ª≠ l√Ω: {len(results)}")

if __name__ == "__main__":
    # Th∆∞ m·ª•c ch·ª©a dataset
    dataset_dir = "E:\\NSFW\\out"
    
    # ƒê∆∞·ªùng d·∫´n l∆∞u file JSON output
    output_path = "E:\\NSFW\\caption_results.json"
    
    # X·ª≠ l√Ω dataset
    process_dataset(dataset_dir, output_path) 